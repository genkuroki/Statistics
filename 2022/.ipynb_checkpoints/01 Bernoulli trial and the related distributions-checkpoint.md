---
jupyter:
  jupytext:
    formats: ipynb,md
    text_representation:
      extension: .md
      format_name: markdown
      format_version: '1.3'
      jupytext_version: 1.10.3
  kernelspec:
    display_name: Julia 1.8.0-beta3
    language: julia
    name: julia-1.8
---

# __Bernoulli試行, 二項分布, 幾何分布, 負の二項分布__

黒木玄

$
\newcommand\op{\operatorname}
\newcommand\R{{\mathbb R}}
\newcommand\var{\op{var}}
\newcommand\std{\op{std}}
$

自明な誤りを見つけたら, 自分で訂正して読んで欲しい.  大文字と小文字の混同や書き直しが不完全な場合や符号のミスは非常によくある.

このノートの内容よりもさらに詳しいノートを自分で作ると勉強になるだろう.  膨大な時間を取られることになるが, このノートの内容に関係することで飯を食っていく可能性がある人にはそのためにかけた時間は無駄にならないと思われる.

```julia
ENV["LINES"], ENV["COLUMNS"] = 100, 100
using Distributions
using StatsPlots
default(fmt = :png, titlefontsize = 10, size = (400, 250))
using Random
Random.seed!(4649373)
using StatsBase
using QuadGK
using SymPy
```

## __一様乱数の繰り返し__


0以上1未満の区間上の一様分布の(擬似)乱数(以下ではこれを __一様乱数__ と短く呼ぶことにする)を10個生成すると以下のようになる.

```julia
[rand() for _ in 1:10]
```

`rand()`は値がランダムに決まる量という意味での確率変数のわかりやすい例になっていると思える.


次のようにもっとシンプルに書ける.

```julia
rand(10)
```

## __Bernoulli試行__

確率 $p$ で $1$ を, 確率 $1-p$ で $0$ をランダムに毎回独立に生成することの繰り返しを __Bernoulli試行__ (ベルヌーイ試行, ベルヌイ試行)と呼ぶ.

Bernoulli試行は乱数の値が $1$ と $0$ しかない場合の乱数列だとみなされる.

```julia
p = 0.3
rand(Bernoulli(p), 20)'
```

これは $1$ が生成される確率が $0.3$ の試行回数30のBernoulli試行の例であり, $1$ の個数の方が $0$ の個数より少なくなっている.


0以上1未満の乱数生成を繰り返して, 乱数が $p$ 未満(以下でもよい)ならば $1$ を生成し, $p$ 以上(「より大きい」でもよい)のとき $0$ を生成することにしてもBernoulli試行が得られる.

```julia
T = rand(20)
```

以下の計算では $T$ の成分が $p = 0.3$ 未満のときに $1$ に, それ以外のときに $0$ に変換している.  これによって, 一様乱数列からBernoulli試行が得られる.

```julia
X = [t < p ? 1 : 0 for t in T]
X'
```

Bernoulli試行に限らず, 何らかの確率分布に従う乱数の生成の独立試行は, 0以上1未満の一様乱数の生成を経由して作ることができる.  その意味でコンピュータでのプログラミングでおなじみの `rand()` 函数は基本的である.


毎回同確率で当たりが出るくじを繰り返し引くことは, 当たりのときに $1$, 外れのときに0とすれば, Bernoulli試行モデルで記述できることの例になっている. 

```julia
[x == 1 ? "当たり" : "外れ" for x in X]
```

ビジネス分野では「当たり」$=1$として, 「広告を見てくれる」「リンクをクリックしてくれる」「商品を購入してくれる」などが「当たり」の例として扱われたりする.

現実の統計分析でBernoulli試行モデルを使う場合には, 「当たり」$=1$がよいことばかりとは限らない.  たとえば, 「病気になる」「死ぬ」「機器が壊れる」などもBernoulli試行モデルで扱われる場合がある. 

現実への応用において, Bernoulli試行モデルはある処置によって生じる「当たり」が出る確率の変化を推定するために使われることが多い.

例えば, 「薬を飲むと病気になる確率が減るか？」とか「ウェブサイトの構成を変えると商品を買ってもらえる確率が上がるか？」などが問題になる.

しかし, Bernoulli試行モデルにおける「すべての場合に同じ確率で独立に当たりまたは外れが生成される」という条件は相当に強い仮定になっており, 多くの場合には非現実的であり, 現実への応用では様々な工夫が必要になる.

統計分析のために用いられる __統計モデルは現実にはぴったり一致していない__ と考えた方がよい. 以下ではこの点について誤解を招きかねない単純化を行う場合が多いので注意して欲しい.  多くの入門的教科書では __統計モデルは現実にはぴったり一致していない__ という実践的に非常に重要なことが強調されていないことが多いので注意が必要である.


## __離散分布__

以下, $a_i$ 達は互いに異なると仮定する.

有限集合 $\{a_1, a_2, \ldots, a_r\}$ または可算集合 $\{a_1, a_2, a_3, \ldots\}$ 上の __離散確率分布__ (もしくは __離散分布__)とは, 0以上の実数達 $p_1, p_2, \ldots, p_r$ または $p_1, p_2, p_3, \ldots$ で総和が $1$ になるものであると定める.  そのとき, $a_i$ を $p_i$ に対応させる函数 $P(a)$ をその離散分布の __確率質量函数__ (probability mass function, pmf)と呼ぶ:

$$
P(a_1) = p_1, \;
P(a_2) = p_3, \;
P(a_3) = p_3, \;
\ldots
$$

直観的には各 $p_i$ はこの離散分布に従う乱数において $a_i$ が確率 $p_i$ で生成されることを意味すると考える.

しかし, 実際の数学的取り扱いでは乱数の「ランダム性」には触れずに単なる「確率の値の表」として $p_1, p_2, \ldots$ を扱うことになる.

例えば, $1,2,3,4$ の値が確率それぞれ $0.1, 0.2, 0.3, 0.4$ で出るルーレットは, $r = 4$,

$$
(a_1, a_2, a_3, a_4) = (1, 2, 3, 4), \quad
(p_1, p_2, p_3, p_4) = (0.1, 0.2, 0.3, 0.4)
$$

で定まる離散分布で自然にモデル化される.


### __離散確率変数__

__離散分布に従う確率変数__ もしくは __離散確率変数__ とは, 確率質量函数 $P(x)$ が定められた有限集合 $\{a_1, a_2, \ldots, a_r\}$ または可算集合 $\{a_1, a_2, a_3, \ldots\}$ 上の実数値函数のことであると定める. (実際には複素数値の確率変数やベクトルや行列に値を持つ確率変数も考えることがある. そのような場合には, 複素数値確率変数, ベクトル値確率変数, 行列値確率変数などと呼ぶことにする.  「分布～に従う確率変数」は "random variable following distribution ～" の翻訳になっている.)

函数のことを「変数」と呼ぶことに違和感を覚える人がいるかもしれないが, 直観的には「確率変数はランダムに値が決まる変数」のように思いたいこともあるので「変数」という呼び方もそう悪くはない.

例えば, $1,2,3,4$ の値が確率それぞれ $0.1, 0.2, 0.3, 0.4$ で出るルーレットのモデル化の離散分布において, 集合 $\{1,2,3,4\}$ 上の任意の実数値函数は離散確率変数になる. 

__確率変数は大文字で表すことが多く, その大文字の確率変数に対応する通常の変数を対応する小文字で表すことが多い.__ 

$x = 1,2,3,4$ のそれぞれにその値自身 $x\in\R$ を対応させる函数が定める確率変数を $X$ と書くことにする. この場合の確率質量函数は $P(x) = 0.1x$ ($x=1,2,3,4$) になる.  この確率変数 $X$ を確率質量函数 $P(x)$ を持つ離散確率変数と呼ぶ.

直観的には, その確率変数 $X$ の値はランダムに決まり, その値は $1,2,3,4$ のそれぞれに確率 $0.1,0.2,0.3,0.4$ でなると考える.  (これはあくまでも直観的な解釈であり, 確率変数は数学的には単なる函数に過ぎない.)

$x\in\{1,2,3,4\}$ をその上の実数 $f(x)\in\R$ に対応させる函数も離散確率変数になる. その確率変数を $f(X)$ と表す.

直観的には, その確率変数 $f(X)$ の値はランダムに決まり, その値は $f(1), f(2), f(3), f(4)$ のそれぞれに確率 $0.1,0.2,0.3,0.4$ でなると考える.  

一般に確率変数 $X$ の函数 $f(X)$ も確率変数になると考えてよい.  (変数の値がランダムに決まるとき, その変数の函数の値もランダムに決まる.  値がランダムに決まると考えたくなるものを確率変数と呼ぶ習慣になっている.)


### __離散確率変数の期待値__

確率変数の最も重要な性質はその期待値が定義されることである.  確率変数の定義を期待値が定義されている変数のことだと思ってもよい.

確率質量函数 $P(x)$ が定められた有限集合 $\{a_1, a_2, \ldots, a_r\}$ または可算集合 $\{a_1, a_2, a_3, \ldots\}$ 上の函数 $f(x)$ が定める離散確率変数を $f(X)$ と書くのであった.  このとき, 離散確率変数 $f(X)$ の __期待値__(expectation value) $E[f(X)]$ が次のように定義される:

$$
E[f(X)] = \sum_i f(a_i)P(a_i).
$$

この和が無限和になる場合には絶対値の期待値 $E[|f(X)|] = \sum_i |f(a_i)|p_i$ が有限の値に収束するとき(すなわち絶対収束するとき)にのみ, 期待値 $E[f(X)] = \sum_i f(a_i)p_i$ が定義されていると考える.  

期待値を __平均__ または __平均値__ と呼ぶこともあるが, あとで定義する標本の平均値と確率変数の平均＝期待値を区別する必要があるので注意が必要である.  混乱しないためには常に「確率変数の平均=期待値」「標本の平均」のように「～の平均」という言い方をすればよいだろう.

例えば, 上のルーレットの例では,

$$
\begin{aligned}
& E[X] = 1\cdot 0.1 + 2\cdot 0.2 + 3\cdot 0.3 + 4\cdot 0.4 = 3, \\
& E[f(X)] = f(1)\cdot 0.1 + f(2)\cdot 0.2 + f(3)\cdot 0.3 + f(4)\cdot 0.4
\end{aligned}
$$

上のルーレットの例で, $1,2,3,4$ の値が出たときに得られる賞金の額がそれぞれ10000円, 3000円, 1000円, 300円のとき, 賞金は次の確率変数 $g(X)$ でモデル化される:

$$
g(1) = 10000, \quad
g(2) = 3000, \quad
g(3) = 1000, \quad
g(4) = 300.
$$

このとき, 賞金 $g(X)$ の期待値は次のように2020円だと計算される:

$$
\begin{aligned}
E[g(X)] &=
g(1)P(1) + g(2)P(2) + g(3)P(3) + g(4)P(4)
\\ & =
10000\cdot 0.1 + 3000\cdot 0.2 + 1000\cdot 0.3 + 300\cdot 0.4
\\ & =
1000 + 600 + 300 + 120 = 2020.
\end{aligned}
$$


### __離散確率変数の期待値を取る操作の基本性質__

確率変数の期待値を取る操作(期待値汎函数) $f(X) \mapsto E[f(X)]$ は以下の性質を満たしている.

* 線形性: $E[\alpha f(X) + \beta g(X)] = \alpha E[f(X)] + \beta E[g(X)]$,
* 単調性: 任意の $x = a_i$ について $f(x)\le g(x)$ ならば $E[f(X)]\le E[g(X)]$,
* 規格化: $E[\alpha] = \alpha$.  (特に $E[1]=1$).

__証明:__ 確率変数 $f(X), g(X)$ と定数 $\alpha,\beta$ について,

$$
\begin{aligned}
E[\alpha f(X) + \beta g(X)] &=
\sum_i(\alpha f(a_i) + \beta g(a_i))p_i
\\ &= 
\sum_i \alpha f(a_i)p_i + \sum_i \beta g(a_i)p_i =
\alpha E[f(X)] + \beta E[g(X)]
\end{aligned}
$$

意の $x = a_i$ について $f(x)\le g(x)$ が成立していると仮定すると,
$$
E[f(X)] = \sum_i f(a_i)p_i \le \sum_i g(a_i)p_i = E[g(X)].
$$

定数 $\alpha$ を定数確率変数とみなすと,
$$
E[\alpha] = \sum_i \alpha p_i = \alpha \sum_i p_i = \alpha.
$$

__証明終.__


### __離散確率変数に関する確率__

$f(X)$ は確率質量函数 $P(x)$ が定められた有限集合 $\{a_1, a_2, \ldots, a_r\}$ または可算集合 $\{a_1, a_2, a_3, \ldots\}$ 上の確率変数であるとする.

このとき, 例えば, $c\le f(X)\le d$ となる確率 $P(c\le f(X)\le d)$ を次のように定める:

$$
P(c\le f(X)\le d) = \sum_{c\le f(a_i)\le d} P(a_i).
$$

確率変数に関する $c\le f(X)\le d$ 以外の条件(例えば $f(X)\ge c$ や $f(X) < d$ など)の確率も同様に定める.

このような確率は, 確率変数 $1_{c\le f(X)\le d}(X)$ を

$$
1_{c\le f(X)\le d}(x) = \begin{cases}
1 & (c\le f(x)\le d) \\
0 & (\text{otherwise})
\end{cases}
$$

と定めると,

$$
P(c\le f(X)\le d) =
\sum_{c\le f(a_i)\le d} P(a_i) =
\sum_i 1_{c\le f(X)\le d}(a_i)P(a_i) =
E[1_{c\le f(X)\le d}(X)]
$$

と期待値で書けるので, 期待値の概念は確率の概念を含んでいるといえる.

例えば, 上のルーレットの例において, 賞金が500円以上5000円以下になる確率は $P(500\le g(X)\le 5000)$ と書け,

$$
P(500 \le g(X) \le 5000) = 0.2 + 0.3 = 0.5
$$

となる. さらに,

$$
1_{500\le g(x)\le 5000}(x) = \begin{cases}
1 & (x = 2, 3) \\
0 & (\text{otherwise})
\end{cases}
$$

となるので,

$$
E[1_{500\le g(X)\le 5000}(X)] =
\sum_{i=1}^4 1_{500\le g(X)\le 5000}(i)P(i) =
0\cdot 0.1 + 1\cdot 0.2 + 1\cdot 0.3 + 0\cdot 0.4 = 0.5
$$

となって, 上の結果と一致する.


### __離散確率変数の分散と標準偏差__

離散確率変数 $Y = f(X)$ の __分散__ (variance) $\var(f(X))$ が次のように定義される:

$$
\var(Y) = E\left[(Y - \mu_{Y})^2\right] = \sum_i (f(a_i) - \mu_Y)^2\,p_i,
\quad \mu_{Y} = E[Y] = E[f(X)].
$$

分散の平方根を __標準偏差__ (standard deviation) と呼ぶ.  確率変数 $Y$ の標準偏差を次のように表すことにする:

$$
\std(Y) = \sqrt{\var(Y)}.
$$

$a > 0$ のとき, $Y$ を $a$ 倍するとその分散は $a^2$ 倍になるが, 標準偏差ならば $Y$ と同じく $a$ 倍される.  こういう性質を持っているので $Y$ と直接比較する場合には $Y$ の分散ではなく標準偏差を使った方が便利である.

確率変数の分散や標準偏差は確率変数が従う分布の __広がりの大きさ__, __確率的揺らぎの大きさ__ の指標の1つになっている.  そのような指標の中で分散は期待値と相性がよい.  (確率変数の期待値(平均)以外の分布の中心を表す値として, 中央値の確率変数版を定義することもでき, 分布の広がりの大きさの指標として, 四分位数の確率変数版を定義することもできる.  期待値(平均)と分散(と標準偏差)の組み合わせと中央値と四分位数の組み合わせは目的と状況に合わせて使い分けることになる.)

確率変数の分散については

$$
\var(Y) = E[Y^2] - E[Y]^2
$$ 

という公式もよく使われる.  この公式は以下のようにして証明される:

$$
\begin{aligned}
\var(Y) &=
E\left[(Y - \mu_{Y})^2\right] =
E\left[Y^2 - 2\mu_Y Y + \mu_{Y}^2\right] =
E[Y^2] - 2\mu_Y E[Y] + \mu_{Y}^2
\\ & =
E[Y^2] - 2\mu_Y \mu_Y + \mu_{Y}^2 =
E[Y^2] - \mu_Y^2 =
E[Y^2] - E[Y]^2.
\end{aligned}
$$

__注意:__ コンピュータによる浮動小数点演算で分散を実装するときには, $\var(Y) = E[Y^2] - E[Y]^2$ という公式を使わずに, 定義式 $E\left[(Y - \mu_{Y})^2\right]$ を使って実装した方が良い可能性がある.  なぜならば, 浮動小数点演算では大きな数の差が小さな値になるとき桁落ちが生じるからである.  同じ程度の大きなの数の差の計算である $Y - \mu_Y$ と違って, $E[Y^2] - E[Y]^2$ は大きな数のあいだの差で計算結果が小さな数になる可能性がある.


#### __問題 (期待値と分散の特徴付け)__

$X$ は有限離散分布に従う確率変数であるとし, 実数 $t$ について $f(t) = E[(X - t)^2]$ とおく.  このとき, $f(t)$ を最小化する $t$ の値は $X$ の期待値 $E[X]$ になり, 最小値 $f(E[X])$ は $X$ の分散 $\var(X)$ になることを示せ.

__解答例:__ 期待値を取る操作の基本性質のみを使って示せる.  $\mu = E[X]$ とおく. このとき,

$$
(X - t)^2 = ((X - \mu) - (t - \mu))^2 = (X - \mu)^2 - 2(t - \mu)(X - \mu) + (t - \mu)^2
$$

なので, これに $E[\;]$ を作用させ, $E[\;]$ の線形性と規格化および $E[X]=\mu$, $E[(X-\mu)^2]=\var(X)$ を使うと,

$$
E[(X - t)^2] =
E[(X - \mu)^2] - 2(t - \mu)(E[X] - \mu) + (t - \mu)^2 =
\var(X)  + (t - \mu)^2.
$$

これより, $f(t)$ は $t = \mu = E[X]$ で最小値 $\var(X)$ になることがわかる.

__解答終__

__注意:__ 上の証明では期待値を取る操作の基本性質しか使っておらず, $X$ が有限離散分布に従う確率変数であることを使っていない.  上の問題の結果は $X$ が有限離散分布に限らないもっと一般の分布に従っている場合にも成立している.

__注意:__ $g(t) = E[|X - t|]$ を最小化する $t$ として確率変数 $X$ の中央値を特徴付けることができる.  ただし, 確率変数の中央値は一般には一意(ただ一つ)には決まらない.  この結果は数学的にそれなりに非自明なので, 数学に自身がある人は確率変数の中央値を自分で適切に定義して, 中央値であることと $g(t)$ を最小化することが同値であることを証明してみよ.

__注意:__ 標本(サンプル, データ)の平均や分散や中央値と確率変数(もしくはそれが従う分布)の平均や分散や中央値の概念を統計学では厳密に区別する必要がある.  混乱しないように注意して欲しい.  混乱を防ぐためには単に「平均」「分散」などと言うことを少な目にして, できるだけ「確率変数の平均や分散」「標本の平均や分散」のように「○○の平均や分散」と言うことにすればよいと思う.


### __カテゴリカル分布__

番号の集合 $\{1,2,\ldots,r\}$ 上の確率質量函数 $P(i) = p_i$ が定める有限離散分布を __カテゴリカル分布__ と呼び, 次のように表す:

$$
\op{Categorical}(p_1, p_2, \ldots, p_r).
$$


`categ = Categorical(0.1, 0.2, 0.3, 0.4)` のとき `rand(categ)` は値が $1,2,3,4$ にそれぞれ確率 $0.1, 0.2, 0.3, 0.4$ でなる確率変数だとみなされる.  (値がランダムに決まる量も確率変数と呼ぶ習慣がある.)  `categ` は上の方で繰り返し使ったルーレットの分布に等しい.

```julia
categ = Categorical(0.1, 0.2, 0.3, 0.4)
```

```julia
@show rand(categ)
@show rand(categ)
@show rand(categ)
@show rand(categ)
@show rand(categ)
@show rand(categ)
@show rand(categ)
@show rand(categ)
@show rand(categ)
@show rand(categ);
```

```julia
bar(support(categ), a -> pdf(categ, a); label="", title="Categorical(0.1, 0.2, 0.3, 0.4)")
```

期待値を取る操作は分布 $\op{dist}$ と確率変数 $f$ に期待値を対応させる函数として定義される.

```julia
function E(f, dist::DiscreteUnivariateDistribution; imax = 10^6)
    sum(a -> f(a) * pdf(dist, a), support(dist)[1:min(end, imax)])
end
```

#### __問題 (ルーレットの例の賞金の期待値と分散)__

ルーレットの例の分布は $\op{Categorical}(0.1, 0.2, 0.3, 0.4)$ であり,  賞金の確率変数 $g(X)$ は

$$
g(1) = 10000, \quad
g(2) = 3000, \quad
g(3) = 1000, \quad
g(4) = 300, \quad
$$

で定義される.  $g(X)$ の期待値と分散を求めよ.

__解答例:__ 以下での計算結果を見よ.


$g(X)$ の期待値:

```julia
E(identity, categ)
```

```julia
g(x) = get((10000, 3000, 1000, 300), x, 0) # x = 1,2,3,4 のそれぞれを 10000, 3000, 1000, 300 に対応させる函数
E(g, categ) # その分布 categ における期待値
```

### __Bernoulli分布__

$0 \le p \le 1$ と仮定する.  値が $1, 0$ になる確率をそれぞれ $p, 1-p$ とすることによって定まる離散分布を __Bernoulli分布__ (ベルヌーイ分布, ベルヌイ分布)と呼び, 次のように表す:

$$
\op{Bernoulli}(p).
$$

この分布の確率質量函数は次のようになる:

$$
P(1) = p, \quad P(0) = 1 - p.
$$

Bernoulli分布に従う確率変数 $X$ の期待値と分散は以下のように計算される:

$$
\begin{aligned}
&
E[X] = \sum_{x=1,0} x p(x) = 1p + 0(1-p) = p,
\\ &
E[X^2] = \sum_{x=1,0} x^2 p(x) = 1^2 p + 0^2(1-p) = p,
\\ &
\var(X) = E[X^2] - E[X]^2 = p - p^2 = p(1-p).
\end{aligned}
$$

```julia
p = 0.3
bern = Bernoulli(p)
```

```julia
[rand(bern) for _ in 1:10]
```

```julia
bar(0:1, x -> pdf(bern, 1 - x); label="", title="Bernoulli(0.3)")
plot!(; xtick=(0:1, 1 .- (0:1)), ytick=0:0.1:1)
```

### __Bernoulli試行の確率分布__

Bernoulli分布 $\op{Bernoulli}(p)$ における $x=1,0$ の確率は

$$
P(x) = p^x (1-p)^{1-x}
$$

と書ける. 実際, $P(1) = p^1(1-p)^0 = p$ となり, $P(0) = p^x (1-p)^{1-x} = p^0(1-p)^1 = 1-p$ となる. これをBernoulli試行の場合に拡張しよう. 

試行回数 $n$ のBernoulli試行の結果は長さ $n$ の $1$ と $0$ からなる数列 $(x_1,\ldots,x_n)$ になる. その個数は, 各々の $x_k$ が2通りでそれらが $n$ 個あるから, $2^n$ 個になる.  ($p=0.5$ の場合を除いて, すべての場合の確率が等しくなるわけではない.)

$x_k=1,0$ ($k=1,2,\ldots,n$)のとき, $n$ 回のBernoulli試行の結果が $(x_1,\ldots,x_n)$ になる確率 $P(x_1,\ldots,x_n)$ は, 毎回同じ確率 $p$ で $1$ が出て確率 $1-p$ で $0$ が出る独立な試行の繰り返しなので, Bernoulli分布における確率の積

$$
P(x_1,\ldots,x_n) = P(x_1)\cdots P(x_n) =
\prod_{k=1}^n \left(p^{x_k} (1-p)^{1-x_k}\right) =
p^{x_1+\cdots+x_n}(1 - p)^{n - (x_1 + \cdots + x_n)}
$$

になると考えられる. (数学的にはこれによってBernoulli試行の離散確率分布を定める.) これは, $x_1,\ldots,x_n$ の中の $1$ (=「当たり」)の個数を $k$ と書くと,

$$
p^k (1-p)^{n-k}
$$

とシンプルに書ける.  このようにして定まる集合 $\{\,(x_1,\ldots,x_n)\mid x_1,\ldots,x_n=1,0\,\}$ 上の離散分布を試行回数 $n$, 成功確率 $p$ の __Bernoulli試行の確率分布__ と呼ぶことにする.

例えば, $n=3$, $p=0.3$ のとき, $(x_1,x_2,x_3)$ を単に並べて $x_1x_2x_3$ と書くと,

* $x_1x_2x_3 = 111$ の確率は $0.3^3=0.027$,
* $x_1x_2x_3 = 011, 101, 110$ の各々の確率は $0.3^2\cdot 0.7 = 0.063$,
* $x_1x_2x_3 = 100, 010, 001$ の各々の確率は $0.3\cdot 0.7^2 = 0.147$,
* $x_1x_2x_3 = 111$ の各々の確率は $0.7^3 = 0.343$.

これら8通りの確率の和は

$$
0.027 + 3\cdot 0.063 + 3\cdot 0.147 + 0.343 =
0.027 + 0.189 + 0.441 + 0.343 = 1
$$

と確かにぴったり $1$ になっている.

```julia
27//1000, 3*63//1000, 3*147//1000, 343//1000
```

```julia
27//1000 + 3*63//1000 + 3*147//1000 + 343//1000
```

### __Bernoulli試行から応用上基本的かつ重要な確率分布が大量に得られること__

Bernoulli試行から以下の確率分布が得られる:

* Bernoulli分布 (= $n=1$ のBernoulli試行の確率分布 = $n=1$ の二項分布)
* 二項分布
* 幾何分布 ($k=1$ の負の二項分布)
* 負の二項分布

これらの連続極限として,

* 正規分布 (二項分布の中心極限定理)
* Poisson分布 (二項分布の時間連続極限)
* ガンマ分布 (負の二項分布の時間連続極限)

も得られる.  この意味でBernoulli試行について深く考察しておけば他の確率分布のことも深く理解できるようになる.


### __二項分布__

__二項分布__ は試行回数 $n$, 成功確率 $p$ のBernoulli試行によって生じる $1$ の個数の分布として得られる.

試行回数 $n$, 成功確率 $p$ のBernoulli試行において $(x_1, x_2, \ldots, x_n)$ が生じる確率は

$$
p^{x_1+\cdots+x_n}(1 - p)^{n - (x_1 + \cdots + x_n)}
$$

であった.  $(x_1,\ldots,x_n)$ ($x_k = 1,0$) でそれが含む $1$ の個数 $x_1 + \cdots + x_n$ が $k$ になるものの個数は

$$
\binom{n}{k} = \frac{n!}{k!(n-k)!}
$$

になるので, 試行回数 $n$, 成功確率 $p$ のBernoulli試行において, $1$ の個数 $x_1 + \cdots + x_n$ が $k$ になる確率は

$$
P(k) = \binom{n}{k} p^k (1 - p)^{n-k} = frac{n!}{k!(n-k)!} p^k (1 - p)^{n-k}
$$

である. この確率質量函数で定義される集合 $\{0,1,\ldots,n\}$ 上の有限離散分布を __二項分布__ と呼び, 次のように表す:

$$
\op{Binomial}(n, p).
$$

二項分布における確率の総和が $1$ になることは二項定理を使えばただちに確認できる:

$$
\sum_{k=0}^n P(k) =
\sum_{k=0}^n \binom{n}{k} p^k (1 - p)^{n-k} =
(p + (1-p))^n = 1.
$$

$K$ は二項分布に従う確率変数であるとする.  このとき, その期待値と分散は以下のように計算される. やはり二項定理を使う.

$$
\begin{aligned}
&
E[K] =
\sum_{k=0}^n k P(k) =
\sum_{k=0}^n k \frac{n!}{k!(n-k)!} p^k (1 - p)^{n-k} =
\sum_{k=1}^n np\frac{(n-1)!}{(k-1)!(n-k)!} p^{k-1} (1 - p)^{n-k}
\\ & \quad =
np \sum_{k=1}^n \binom{n-1}{k-1} p^{k-1} (1 - p)^{n-k} =
np (p + (1-p))^{n-1} =
np,
\\ &
E[K(K-1)] =
\sum_{k=0}^n k(k-1) P(k) =
\sum_{k=2}^n k(k-1) \frac{n!}{k!(n-k)!} p^k (1 - p)^{n-k} =
\sum_{k=1}^n n(n-1)p^2\frac{(n-2)!}{(k-2)!(n-k)!} p^{k-2} (1 - p)^{n-k}
\\ & \quad =
n(n-1)p^2 \sum_{k=2}^n \binom{n-2}{k-2} p^{k-2} (1 - p)^{n-k} =
n(n-1)p^2 (p + (1-p))^{n-2} =
n(n-1)p^2,
\\ &
E[K(K-1)] = E[K^2] - E[K], 
\\ &
E[K^2] = E[K(K-1)] + E[K] = n(n-1)p^2 + np = n^2 p^2 - n p^2 + np = np(1-p) + n^2 p^2,
\\ &
\var(K) = E[K^2] - E[K]^2 = np(1-p) + n^2 p^2 - (np)^2 = np(1-p).
\end{aligned}
$$

__注意:__ 二項分布 $\op{Binomial}(n, p)$ に従う確率変数の期待値 $np$ と分散 $np(1-p)$ は $n=1$ の場合のBernoulli分布 $\op{Bernoulli}(p)$ の期待値と $p$ と分散 $p(1-p)$ のちょうど $n$ 倍になっている.  これは偶然ではなく, 必然的にこうなる理由がある. この点については後で確率変数の独立性について説明してから詳しく説明する.

```julia
bin = Binomial(16, 0.3)
x = support(bin)
bar(x, x -> pdf(bin, x); label="", title="Binomial(20, 0.3)")
plot!(; xtick=x)
```

### __幾何分布__

$0< p \le 1$ であると仮定し, $m=0,1,2,\ldots$ であるとする.

確率 $p$ で $1$ が確率 $1-p$ で $0$ が生じるようなBernoulli試行を続けたとき, ちょうど $m+1$ 回目で $1$ が初めて出る確率は, 
$m$ 回 $0$ が続いて $m+1$ 回目に $1$ が出る確率

$$
(1-p)^m \times p
$$

に等しいので,

$$
P(m) = p(1 - p)^m
$$

になる.  この確率質量函数で定義される可算集合 $\{0,1,2,\ldots\}$ 上の無限離散分布を __幾何分布__ (geometric distribution)と呼び, 次のように表す:

$$
\op{Geometric}(p).
$$

幾何分布における確率の総和が $1$ になることは次のようにして証明される:

$$
\sum_{m=0}^\infty p(m) = 
p \sum_{m=0}^\infty (1 - p)^m =
\frac{p}{1 - (1 - p)} = 1.
$$

幾何分布に従う確率変数 $M$ の期待値と分散は以下のように計算される.

上の計算から

$$
\sum_{m=0}^\infty (1 - p)^m = \frac{1}{p}
$$

となることもわかる.  両辺を $p$ で微分して $-1$ 倍する操作を2回施すと,

$$
\sum_{m=1}^\infty m(1-p)^{m-1} = \frac{1}{p^2}, \quad
\sum_{m=2}^\infty m(m-1)(1-p)^{m-2} = \frac{2}{p^3}.
$$

これらの公式を使うと,

$$
\begin{aligned}
&
E[M] = \sum_{m=0}^\infty m P(m) =
\sum_{m=1}^\infty m p (1-p)^m = 
p(1-p)\sum_{m=1}^\infty m(1-p)^{m-1} =
p(1-p)\frac{1}{p^2}
\frac{1-p}{p},
\\ &
E[M(M-1)] =
\sum_{m=0}^\infty m(m-1) P(m) =
\sum_{m=2}^\infty m(m-1) p(1-p)^m
\\ & \quad =
p(1-p)^2 \sum_{m=2}^\infty m(m-1)(1-p)^{m-2} =
p(1-p)^2 \frac{2}{p^3} =
\frac{2(1-p)^2}{p^2}
\\ &
E[M(M-1)] = E[M^2] - E[M],
\\ &
E[M^2] = E[M(M-1)] + E[M] = \frac{2(1-p)^2}{p^2} + \frac{1-p}{p},
\\ &
\var(M) = E[M^2] - E[M]^2 =
\frac{2(1-p)^2}{p^2} + \frac{1-p}{p} - \frac{(1-p)^2}{p^2} =
\frac{(1-p)^2}{p^2} + \frac{p(1-p)}{p^2} =
\frac{1-p}{p^2}.
\end{aligned}
$$

$N = M+1$ とおく.  $N$ は始めて $1$ が出るまでの試行回数を意味する確率変数になる. $N$ の確率質量函数は

$$
P(n-1) = p(1-p)^{n-1}
$$

になる. $N$ の期待値と分散は上の結果より,

$$
E[N] = E[M] + 1 = \frac{1}{p},
\quad
\var(N) = \var(M) = \frac{1-p}{p^2}.
$$

となる.

```julia
geom = Geometric(0.3)
x = 0:16
bar(x, x -> pdf(geom, x); label="", title="Geometric(0.3)")
plot!(; xtick = x)
```

### __負の二項展開__

任意の数 $a$ と0以上の整数 $m$ について, 二項係数を

$$
\binom{a}{m} = \frac{a(a-1)(a-2)\cdots(a-m+1)}{m!}
$$

と定める. たとえば, $a = n$ も0以上の整数のとき,

$$
\binom{n}{m} = \frac{n!}{m!(n-m)!}
$$

となり, $m=0,1,2,3$ の場合には,

$$
\binom{a}{0} = 1, \;
\binom{a}{1} = a, \;
\binom{a}{2} = \frac{a(a-1)}{2}, \;
\binom{a}{3} = \frac{a(a-1)(a-2)}{3!}.
$$

$f(x) = (1 + x)^a$ について,

$$
f'(x) = a(1+x)^{a-1}, \;
f''(x) = a(a-1)(1+x)^{a-2}, \;
\ldots\,\;
f^{(m)}(x) = a(a-1)\cdots(a-m+1)(1+x)^{a-m}
$$

なので,

$$
f^{(m)}(0) = a(a-1)\cdots(a-m+1), \quad
\frac{1}{m!}f^{(m)}(0) = \binom{a}{m}.
$$

ゆえに, $f(x)=(1+x)^a$ は $x=0$ で次のようにTaylor展開される:

$$
(1+x)^a = f(x) =
\sum_{m=0}^\infty \frac{1}{m!}f^{(m)}(0) x^m =
\sum_{m=0}^\infty \binom{a}{m} x^m =
1 + ax + \frac{a(a-1)}{2}x^2 + \frac{a(a-1)(a-2)}{3!}x^3 + \cdots
$$

このTaylor展開は $|x|<1$ で常に収束している. $a=n$ が0以上の整数の場合には $m=0,1,\ldots,n$ に関する有限和になり, 通常の二項定理が得られる.  このTaylor展開を __二項展開__ と呼ぶ.

次の形の二項係数を __負の二項係数__ と呼ぶことにする:

$$
(-1)^m\binom{-a}{m} = (-1)^m\frac{(-a)(-a-1)\cdots(-a-m+1)}{m!} =
\frac{a(a+1)\cdots(a+m-1)}{k!} = \binom{a+m-1}{k!}.
$$

二項展開より, $|x|<1$ のとき,

$$
(1 - x)^{-a} = \sum_{m=0}^\infty (-1)^m\binom{-a}{m}x^m =
\sum_{m=0}^\infty \binom{a+m-1}{m} x^m.
$$

この公式を __負の二項展開__ と呼ぶことにする.


### __負の二項分布__

$0< p \le 1$ であると仮定し, $k$ は正の整数であるとし, $m=0,1,2,\ldots$ であるとする.

確率 $p$ で $1$ が確率 $1-p$ で $0$ が生じるようなBernoulli試行を続けたとき, $1$ が合計でちょうど $k$ 個出たときの試行回数が $k + m$ になる確率は, 最初の $k+m-1$ 回中の $0$ の個数が $m$ 個で最後の $m+k$ 回目に $1$ が出る確率

$$
\binom{k+m-1}{m} p^{k-1}(1-p)^m \times p
$$

に等しいので,

$$
P(m) = \binom{k+m-1}{m} p^k (1 - p)^m = (-1)^m\binom{-k}{m} p^k (1 - p)^m
$$

になる.  この確率質量函数で定義される可算集合 $\{0,1,2,3,\ldots\}$ 上の無限離散分布を __負の二項分布__ (negative binomial distribution)と呼び, 次のように表す:

$$
\op{NegativeBinomial}(k, p).
$$

負の二項分布における確率の総和が $1$ になることは, 前節の負の二項展開からただちに得られる:

$$
\sum_{m=0}^\infty P(m) =
p^k \sum_{m=0}^\infty \binom{k+m-1}{m}(1 - p)^m =
p^k (1 - (1 - p))^{-k} = p^k p^{-k} = 1.
$$

二項係数について

$$
\begin{aligned}
&
m\binom{a+m-1}{m} =
m\frac{a(a-1)\cdots(a+m-1)}{m!}
\\ & \quad =
a\frac{(a-1)\cdots(a-m+1)}{(m-1)!} =
a\binom{a+m-1}{m-1},
\\ &
m(m-1)\binom{a+m-1}{m} =
m(m-1)\frac{a(a-1)(a-2)\cdots(a+m-1)}{m!}
\\ & \quad =
a(a-1)\frac{(a-2)\cdots(a+m-1)}{(m-2)!} =
a(a-1)\binom{a+m-1}{m-2}
\end{aligned}
$$

が成立することとと負の二項展開を使うと, 負の二項分布に従う確率変数 $M$ の期待値と分散は以下のように計算される:


$$
\begin{aligned}
&
E[M] = \sum_{m=0}^\infty m P(m) =
p^k \sum_{m=1}^\infty m\binom{k+m-1}{m}(1 - p)^m =
p^k \sum_{m=1}^\infty k\binom{k+m-1}{m-1}(1 - p)^m 
\\ & \quad =
p^k k(1-p)\sum_{m=1}^\infty \binom{(k+1)+(m-1)-1}{m-1}(1 - p)^{m-1} =
p^k k(1-p) (1-(1-p))^{-(k+1)}
\\ & \quad =
p^k k(1-p) p^{-(k+1)} =
\frac{k(1-p)}{p},
\\ &
E[M(M-1)] = \sum_{m=0}^\infty m(m-1) P(m) =
p^k \sum_{m=2}^\infty m(m-1)\binom{k+m-1}{m}(1 - p)^m =
p^k \sum_{m=2}^\infty k(k-1)\binom{k+m-1}{m-2}(1 - p)^m
\\ & \quad =
p^k k(k-1)(1-p)^2\sum_{m=1}^\infty \binom{(k+2)+(m-2)-1}{m-2}(1 - p)^{m-2} =
p^k k(k-1)(1-p)^2 (1-(1-p))^{-(k+2)}
\\ & \quad =
p^k k(k-1)(1-p)^2 p^{-(k+2)} =
\frac{k(k-1)(1-p)^2}{p^2},
\\ &
E[M(M-1)] = E[M^2] - E[M],
\\ &
E[M^2] = E[M(M-1)] + E[M] =
\frac{k(k-1)(1-p)^2}{p^2} + \frac{k(1-p)}{p},
\\ &
\var(M) = E[M^2] - E[M]^2 =
\frac{k(k-1)(1-p)^2}{p^2} + \frac{k(1-p)}{p} - \frac{k^2(1-p)^2}{p^2}
\\ & \quad =
\frac{-k(1-p)^2}{p^2} + \frac{kp(1-p)}{p^2} =
\frac{k(1-p)}{p^2}.
\end{aligned}
$$

$N=M+k$ とおく. $N$ は $1$ が合計でちょうど $k$ 個出たときの試行回数を意味する確率変数であり, その確率質量函数は

$$
P(n-k) = \binom{n-1}{n-k} p^k (1 - p)^{n-k} = \binom{n-1}{k-1} p^k (1 - p)^{n-k}
$$

になる(この形は二項分布の確率質量函数に近いが少しだけ違っている). 上の結果より, $N$ の期待値と分散は次のようになる:

$$
E[N] = E[M] + k = \frac{k}{p}, \quad
\var(N) = \var(M) = \frac{k(1-p)}{p^2}.
$$

__注意:__ 負の二項分布に従う確率変数の期待値と分散は $k=1$ の場合の幾何分布の期待値と分散のちょうど $k$ 倍になっている.  これは偶然ではなく, 必然的にこうなる理由がある. この点については後で確率変数の独立性について説明してから詳しく説明する. 

__注意:__ 以上の計算は $k$ が正の整数でなくても,

$$
\binom{k+m-1}{m} = \frac{k(k+1)\cdots(k+m-1}{m!} > 0 \quad (k > 0,\; m = 0,1,2,3,\ldots)
$$

なので, $k>0$ ならば確率質量函数

$$
P(m) = \binom{k+m-1}{m} p^k (1 - p)^m = (-1)^m\binom{-k}{m} p^k (1 - p)^m
\quad (m=0,1,2,3,\ldots)
$$

は定義されている. 期待値と分散の計算も上で計算した結果と同じになる. このように拡張された離散分布も負の二項分布と呼ばれる.

```julia
negbin = NegativeBinomial(10, 0.5)
μ, σ = mean(negbin), std(negbin)
x = 0:round(Int, μ + 4σ)
bar(x, x -> pdf(negbin, x); label="", title="NegativeBinomial(10, 0.5)")
plot!(; xtick=0:5:maximum(x)+5)
```

## __連続的確率分布 (連続分布)__


$a, b\in \R\cup\{\pm\infty\}$, $a<b$ であるとし, 区間 $(a, b) = \{\,x\in\R\mid a<x<b\,\}$ を考える. ($a=-\infty$ や $b=\infty$ となっている場合があるので注意せよ.) このとき, 実数 $x\in (a, b)$ を0以上の実数に対応させる函数 $p(x)$ で

$$
\int_a^b p(x)\,dx = 1
$$

を満たすものを区間 $(a, b)$ 上の __確率密度函数__ (probability density function, pdf)と呼ぶ. 

密度函数の定義域を実数全体に拡張する場合には区間 $(a, b)$ の外での値は $0$ にする.

区間 $(a, b)$ 上の確率密度函数が与えられているとき, 区間 $(a, b)$ 上の __連続確率分布__ (もしくは __連続分布__)が与えられているいう.　(区間の両端を区間に含めても含めなくてもよいが, 連続分布の場合にはその違いを気にする必要はない.  なぜならば, 連続分布において一点の確率は0だからである.)

1次元の区間を $n$ 次元の $\R^n$ における領域に一般化して, $n$ 変量の連続分布を定義することもできる. その場合には上の積分は $n$ 重積分になる.


### ___一様分布___

区間 $(a, b)$ 上の確率密度函数

$$
p(x) = \frac{1}{b - a} \quad (a < x < b)
$$

によって与えられる連続分布を区間 $(a, b)$ 上の一様分布と呼び, 次のように表す:

$$
\op{Uniform}(a, b).
$$

半開区間 $[a, b)$, $(a, b]$ や閉区間 $[a, b]$ 上の一様分布も同様に定義されるが, 区間の両端を含めるか否かは本質的ではない.

コンピュータでの `rand()` 函数は近似的に区間 $[0, 1)$ 上の一様分布に従う確率変数とみなされる.

```julia
plot(Uniform(0, 1), -0.4, 1.4; label="", title="Uniform(0, 1)")
```

### __正規分布__

$\mu \in \R$, $\sigma \in \R$, $\sigma > 0$ と仮定する.  実数直線 $\R = (-\infty, \infty)$ 上の確率密度函数

$$
p(x) = \frac{1}{\sqrt{2\pi\sigma^2}}\exp\left(-\frac{(x - \mu)^2}{2\sigma^2}\right)
$$

によって与えられる連続分布を平均 $\mu$, 分散 $\sigma^2$ の __正規分布__ と呼び, 

$$
\op{Normal}(\mu, \sigma)
$$

と表す.  パラメータ $\sigma$ は標準偏差と呼ばれる.

特に平均 $0$, 分散 $1$ の正規分布を __標準正規分布__ と呼び, $\op{Normal}() = \op{Normal}(0,1)$ と表すことにする.

__分布のパラメータとしての平均 $\mu$ や分散 $\sigma^2$ と後で出て来る標本の平均や分散を概念的に厳密に区別する必要がある.__

同じような用語で呼ぶことが原因で初学者は大抵の場合混乱する. 

__混乱せずに済むためには__ 「平均」や「分散」という用語を使う場合には必ず「○○分布の平均と分散」や「確率変数○○の平均と分散」や「標本○○の平均と分散」のように __「～の平均と分散」という言い方をすればよい.__

```julia
plot(Normal(2, 3), 2-4*3, 2+4*3; label="", title="Normal(2, 3)", xtick=-100:2:100)
```

```julia
plot(Normal(), -4, 4; label="", title="Normal()", xtick=-100:100)
```

### __連続確率変数__

区間 $(a, b)$ 上の確率密度函数 $p(x)$ が与えられているとする.

さらに, 区間 $(a, b)$ 上の実数値函数を __連続分布の確率変数__ または __連続確率変数__ と呼ぶ. (積分が定義できるような良い函数に限ることにする. 複素数値, ベクトル値, 行列値の確率変数を考えることもある.)

たとえば, $x\in(a,b)$ をそれ自身 $x\in\R$ に対応させる函数は確率変数とみなされる. 以下ではそれを $X$ と書き, 確率密度函数 $p(x)$ を持つ確率変数と呼ぶ.  その確率密度函数で与えられる連続分布の名前が $D$ のとき, $X$ は分布 $D$ に従う確率変数であるという(「従う」は "follow" の訳語).


### __連続確率変数に関する確率とその期待値__

連続分布において, 値が $a \le c\le d \le b$ のとき, $c$ より大きく $d$ より小さくなる確率 $P(c < X < d)$ を

$$
P(c < X < d) = \int_c^d p(x)\,dx
$$

と積分で定義する.  $c$ 以上 $d$ 以下の確率 $P(c\le X \le d)$ なども同じ積分の値で定義する.  

特に値がぴったり $c$ に等しくなる確率 $P(X = c)$ は次のように $0$ になる:

$$
P(X = c) = P(c\le X\le c) = \int_c^c p(x)\,dx = 0.
$$

$x\in(a, b)$ を含む区間 $(a, b)$ 内の長さ $dx$ の微小区間 $I = (x - t\,dx, x + u\,dx)$ ($t,u\ge 0$, $t+u=1$) に値が含まれる確率は

$$
P(X \in I) = \int_{x-t\,dx}^{x+u\,dx} p(x')\,dx' \approx p(x)\,dx
$$

のように近似される. これが確率密度の密度の意味である.

確率変数 $f(X)$ の期待値 $E[f(X)]$ が次のように定義される:

$$
E[f(X)] = \int_a^b f(x)p(x)\,dx.
$$

ただし, これは $\int_a^b |f(x)|p(x)\,dx$ が有限の値に収束する場合(積分が絶対収束する場合)にのみ定義されていると考える.

期待値を __平均__ または __平均値__ と呼ぶこともあるが, あとで定義する標本の平均値と確率変数の平均＝期待値を区別する必要があるので注意が必要である.

確率変数 $1_{c\le f(X)\le d}(X)$ を

$$
1_{c\le f(X)\le d}(x) = \begin{cases}
1 & (c\le x\le d) \\
0 & (\text{otherwise})
\end{cases}
$$

と定めると,

$$
E[1_{c\le f(X)\le d}(X)] = \int_a^b 1_{c\le f(X)\le d}(x)p(x)\,dx =
\int_c^d p(x)\,dx = P(c\le X\le d).
$$

このように期待値の概念は確率の概念を含んでいると考えてよい.


### __連続確率変数の期待値を取る操作の基本性質__

連続確率変数の期待値を取る操作(期待値汎函数) $f(X) \mapsto E[f(X)]$ は以下の性質を満たしている.

* 線形性: $E[\alpha f(X) + \beta g(X)] = \alpha E[f(X)] + \beta E[g(X)]$,
* 単調性: 任意の $x = a_i$ について $f(x)\le g(x)$ ならば $E[f(X)]\le E[g(X)]$,
* 規格化: $E[\alpha] = \alpha$.  (特に $E[1]=1$).

この性質はすでに説明した離散確率変数の基本性質と完全に同じ形をしており, 離散の場合の和を積分に置き換えれば全く同じ方法で証明される.


### __連続確率変数の分散__

連続確率変数 $Y = f(X)$ の __分散__(variance) $\var(f(X))$ が次のように定義される:

$$
\var(Y) = E\left[(Y - \mu_{Y})^2\right] = \int_a^b (f(x) - \mu_Y)^2p(x)\,dx,
\quad \mu_{Y} = E[Y] = E[f(X)].
$$

これが $\var(Y) = E[Y^2] - E[Y]^2$ を満たすことを離散の場合と完全に同様に証明できる.

連続確率変数 $Y$ の場合もその標準偏差を $\std(Y) = \sqrt{\var(Y)}$ と定める.


### __確率変数の一次函数の期待値と分散__

離散および連続な確率変数 $Y$ と定数 $a$, $b$ について,

$$
E[aY + b] = a E[Y] + b, \quad \var(aY+b) = a^2\var(Y) 
$$

となることを以下のようにして, $E[\;]$ の基本性質の線形性と規格化の条件のみを使って示せる.

$$
\begin{aligned}
&
E[aY + b] = aE[Y] + E[b] = aE[Y] + b. 
\\ &
\var(aY + b) = E[(aY + b - (aE[Y] + b))^2]
\\ & \qquad = E[a^2(Y - E[Y])^2] = a^2 E[(Y - E[Y])^2] = a^2\var(Y).
\end{aligned}
$$


### __一様分布の期待値と分散__

区間 $(a, b)$ 上の確率密度函数

$$
p(x) = \frac{1}{b - a} \quad (a < x < b)
$$

によって与えられる一様分布を考え, $X$ はこの分布に従う確率変数であるとする.

このとき, $X$ の期待値(平均) $\mu$ と分散 $\sigma^2$ は以下のように計算される:

$$
\begin{aligned}
&
\mu =
E[X] = \int_a^b x p(x)\,dx =
\frac{1}{b-a}\int_a^b x\,dx = \frac{b^2 - a^2}{2(b - a)} = \frac{a+b}{2}.
\\ &
E[X^2] = \int_a^b x^2 p(x)\,dx =
\frac{1}{b-a}\int_a^b x^2\,dx = \frac{b^3 - a^3}{3(b-a)} = \frac{a^2 + ab + b^2}{3}.
\\ &
\var(X) = E[X^2] - E[X]^2 = 
\frac{4(a^2+ab+b^2) - 3(a+b)^2}{12} =
\frac{a^2-2ab+b^2}{12} =
\frac{(b-a)^2}{12}.
\end{aligned}
$$

```julia
function E(f, dist::ContinuousUnivariateDistribution)
    quadgk(x -> f(x) * pdf(dist, x), extrema(dist)...)[1]
end
```

```julia
mean(Uniform(0, 1//0)), var(Uniform(0, 1//1))
```

```julia
E(x -> x, Uniform(0, 1)), E(x -> x^2, Uniform(0, 1)) - E(x -> x, Uniform(0, 1))^2
```

```julia
mean(Uniform(0, 5//1)), var(Uniform(0, 5//1))
```

```julia
E(x -> x, Uniform(0, 5)), E(x -> x^2, Uniform(0, 5)) - E(x -> x, Uniform(0, 5))^2
```

### __標準正規分布の期待値と分散__

$Z$ は標準正規分布に従う確率変数であるとする. このとき $Z$ は確率密度函数

$$
p(z) = \frac{1}{\sqrt{2\pi}}e^{-z^2/2}
$$

を持つ.  このとき, $z e^{-z^2/2}$ が奇函数であり, 奇函数の $\R$ 全体での積分は $0$ になるので,

$$
E[Z] = \frac{1}{\sqrt{2\pi}} \int_{-\infty}^\infty x e^{-z^2/2}\,dz = 0.
$$

$z^2 e^{-z^2/2}$ が偶函数であることと, $z = x^{1/2}$ と変数変換すると, $dz = x^{-1/2}\,dx/2$ となることを使うと, 

$$
\begin{aligned}
\var(Z) &= E[Z^2] =
\frac{1}{\sqrt{2\pi}} \int_{-\infty}^\infty z^2 e^{-z^2/2}\,dz =
\frac{2}{\sqrt{2\pi}} \int_0^\infty z^2 e^{-z^2/2}\,dz
\\ &=
\frac{2}{\sqrt{2\pi}} \int_0^\infty x e^{-x/2} \frac{x^{-1/2}\,dx}{2} =
\frac{1}{\sqrt{2\pi}} \int_0^\infty x^{1/2 - 1} e^{-x/2}\,dx =
\frac{2^{1/2}\Gamma(1/2)}{\sqrt{2\pi}} = 1.
\end{aligned}
$$

ここで, 5番目の等号では次の公式を使った:

$$
\int_0^\infty x^{\alpha - 1} e^{-x/\theta}\,dx = \theta^\alpha \Gamma(\alpha) \quad (\alpha, \theta > 0).
$$

最後の等号では $\Gamma(1/2)=\sqrt{\pi}$ を使った. ガンマ函数はこれらの形で使われることが多い. これらの辺の公式については別のノートで解説することにする.

平均 $\mu$ と分散 $\sigma^2$ を持つ正規分布に従う確率変数 $X$ は $X = \mu + \sigma Z$ と作れる.

```julia
mean(Normal(0, 1//1)), var(Normal(0, 1//1))
```

```julia
E(x -> x, Normal(0, 1)), E(x -> x^2, Normal(0, 1)) - E(x -> x, Normal(0, 1))^2
```

```julia
mean(Normal(2, 3//1)), var(Normal(2, 3//1))
```

```julia
E(x -> x, Normal(2, 3)), E(x -> x^2, Normal(2, 3)) - E(x -> x, Normal(2, 3))^2
```

標準正規分布の歪度(わいど, skewness):

```julia
E(z -> z^3, Normal())
```

標準正規分布の尖度(せんど, kurtosis)に $3$ を足した値:

```julia
E(z -> z^4, Normal())
```

尖度の定義でどうして $3$ を足しておくか:

```julia
@syms t κ3 κ4 κ5 μ3 μ4 μ5
series(exp(t^2//2 + κ3 * t^3//6 + κ4 * t^4//24 + κ5 * t^5//120), t)
```

```julia
series(log(1 + t^2//2 + μ3 * t^3//6 + μ4 * t^4//24 + μ5 * t^5//120), t)
```

```julia

```
